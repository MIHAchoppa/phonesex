#!/usr/bin/env python3
"""
Demo script showing how the chatline application works
This simulates the user experience without requiring a real API key
"""

import os
os.environ['GROQ_API_KEY'] = 'demo_key'

from chatline import PersonalityPresets, print_welcome, print_menu

def print_demo_interaction():
    """Print a demonstration of the chatline interaction"""
    
    print_welcome()
    print("Current personality: Flirty")
    print_menu()
    
    print("\n" + "="*60)
    print("DEMO INTERACTION")
    print("="*60)
    
    # Simulate conversation
    interactions = [
        ("You: Hey there!", 
         "AI: Well hello there, gorgeous! I've been waiting for someone interesting\nlike you to come along... ðŸ˜‰ What brings you to my corner of the world\ntonight?"),
        
        ("\nYou: /personalities",
         """
âœ¨ Available Personalities:
  â˜… 1. Flirty
    2. Romantic
    3. Adventurous
    4. Mysterious
    5. Playful

Enter personality number (or press Enter to cancel): 2

âœ¨ Personality changed to: Romantic
Starting a fresh conversation...
"""),
        
        ("You: Tell me something sweet",
         "AI: You know, there's something truly special about this moment we're\nsharing. In a world that moves so fast, finding someone who wants to\nconnect on a deeper level is like discovering a hidden treasure. Your\npresence here makes my heart flutter with excitement... ðŸ’•"),
        
        ("\nYou: /stats",
         """
ðŸ“Š Conversation Stats:
  Messages exchanged: 2
  Current personality: Romantic
  Model: llama-3.1-70b-versatile
"""),
        
        ("You: /quit",
         "\nðŸ‘‹ Thanks for chatting! Goodbye!\n")
    ]
    
    for user_input, ai_response in interactions:
        print(f"\n{user_input}")
        print(ai_response)
    
    print("\n" + "="*60)
    print("FEATURES DEMONSTRATED")
    print("="*60)
    print("""
âœ“ Ultra-fast streaming responses (powered by GROQ LPU)
âœ“ Multiple AI personalities (5 unique conversation styles)
âœ“ Interactive commands (/personalities, /clear, /stats, /quit)
âœ“ Conversation context maintenance
âœ“ Real-time response streaming
âœ“ Easy personality switching
âœ“ Conversation statistics tracking

HOW TO USE WITH REAL GROQ API:
1. Get a free API key from https://console.groq.com/
2. Copy .env.example to .env
3. Add your GROQ_API_KEY to .env
4. Run: python chatline.py
5. Start chatting!

GROQ API ADVANTAGES:
â€¢ 300+ tokens/second processing speed
â€¢ Sub-second response times
â€¢ Multiple model options (Llama, Mixtral, Gemma)
â€¢ Real-time streaming support
â€¢ Free tier available
â€¢ OpenAI-compatible API
""")

if __name__ == "__main__":
    print_demo_interaction()
